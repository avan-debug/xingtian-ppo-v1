agent:
  agent_config:
    complete_step: 10000000
    max_steps: 128
  agent_name: AtariPpo2
  agent_num: 1
alg:
  alg_config:
    agent_num: 1
    api_type: standalone
    env_attr:
      agent_ids: &id001
      - 0
      api_type: standalone
      episode_limit: 300
      n_actions: 7
      n_agents: 2
      obs_shape: 17
      state_shape: 27
    instance_num: 3
    prepare_times_per_train: 36
  alg_name: PPO
  model_info:
    actor:
      action_dim: 4
      gpu_config:
        cluster:
          peers: null
        self:
          rank: null
      infer_batch: 12
      input_dtype: uint8
      model_config:
        BATCH_SIZE: 320
        CRITIC_LOSS_COEF: 1.0
        ENTROPY_LOSS: 0.003
        LOSS_CLIPPING: 0.1
        LR: 0.00025
        MAX_GRAD_NORM: 5.0
        NUM_SGD_ITER: 4
        SUMMARY: false
        VF_SHARE_LAYERS: true
        action_type: Categorical
        activation: relu
        agent_ids: *id001
        api_type: standalone
        episode_limit: 300
        gpu_nums: 2
        hidden_sizes:
        - 256
        n_actions: 7
        n_agents: 2
        obs_shape: 17
        state_shape: 27
      model_name: PpoCnnLiteV3
      quantization: true
      state_dim:
      - 84
      - 84
      - 4
      type: learner
archive_root: ./logs_compare_p_q_test
bm_board: null
bm_eval: {}
bm_id: p_q
config_yaml: /home/xys/xingtian-ppo-v1/logs_compare_p_q_test/p_q+220927222351T0/benchmark/train_config.template
env:
  env_info:
    name: BreakoutNoFrameskip-v4
    size: 12
    thread_affinity_offset: 0
    wait_nums: 12
  env_name: EnvPool
eval_gap: 200
record_csv: /home/xys/xingtian-ppo-v1/logs_compare_p_q_test/p_q+220927222351T0/benchmark/records.csv
start_time: 2022-09-27 22:23:51.399086
workspace: /home/xys/xingtian-ppo-v1/logs_compare_p_q_test/p_q+220927222351T0/benchmark
